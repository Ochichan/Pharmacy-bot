import os
import pandas as pd
import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.tools import tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_tool_calling_agent
from langchain.agents.agent import AgentExecutor
import altair as alt

# --- API KEY ë° í˜ì´ì§€ ì„¤ì • ---
if "GEMINI_API_KEY" in st.secrets:
    api_key = st.secrets["GEMINI_API_KEY"]
else:
    api_key = "YOUR_API_KEY_HERE"

st.set_page_config(
    page_title="ì•½êµ­ ë˜‘ë˜‘ì´ ë¹„ì„œ v2.0",
    page_icon="ğŸ’Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- UI ë””ìì¸ (CSS) ---
def inject_custom_css():
    st.markdown("""
    <style>
    html, body, [class*="css"] {
        font-family: 'Pretendard', sans-serif;
        font-size: 18px;
    }
    .stApp { background-color: #f8fafc; color: #1e293b !important; }
    [data-testid="stSidebar"] { background-color: #ffffff; border-right: 1px solid #e2e8f0; }
    [data-testid="stSidebar"] h1, h2, h3 { color: #2563eb !important; }
    div[data-testid="stMetric"] {
        background-color: #ffffff;
        padding: 20px;
        border-radius: 15px;
        border: 1px solid #e2e8f0;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        text-align: center;
    }
    div[data-testid="stMetric"] label { color: #64748b !important; font-size: 1.1rem !important; }
    div[data-testid="stMetric"] div[data-testid="stMetricValue"] { color: #2563eb !important; font-size: 2.2rem !important; font-weight: 800; }
    .stChatMessage { background-color: #ffffff; border-radius: 15px; padding: 15px; margin-bottom: 10px; border: 1px solid #e2e8f0; box-shadow: 0 2px 4px rgba(0,0,0,0.05); }
    [data-testid="stChatMessageAvatarUser"] { background-color: #fbbf24; }
    [data-testid="stChatMessageAvatarAssistant"] { background-color: #3b82f6; }
    h1, h2, h3 { color: #1e293b; font-weight: 700; }
    </style>
    """, unsafe_allow_html=True)

inject_custom_css()

# --- LangChain ë„êµ¬ ë° ë¡œì§ ---
@st.cache_resource
def initialize_llm(api_key):
    return ChatGoogleGenerativeAI(
        model="gemini-2.0-flash-exp",
        api_key=api_key,
        temperature=0,
    )

@tool
def analyze_financial_data(question: str):
    """ì—‘ì…€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•©ë‹ˆë‹¤."""
    try:
        df = st.session_state['df']
        selected_year = st.session_state.get('selected_year', None)
        
        df['ê¸ˆì•¡'] = pd.to_numeric(df['ê¸ˆì•¡'], errors='coerce').fillna(0)
        if selected_year:
            df = df[df['ë…„'] == selected_year]

        income_grp = df[df['ëŒ€ë¶„ë¥˜'] == 'ìˆ˜ì…'].groupby(['ì›”'])['ê¸ˆì•¡'].sum()
        expense_grp = df[df['ëŒ€ë¶„ë¥˜'].isin(['ê³ ì •ë¹„ìš©', 'ì˜ì•½í’ˆ_êµ¬ì…ë¹„'])].groupby(['ì›”'])['ê¸ˆì•¡'].sum()
        
        summary_text = "### ì›”ë³„ ìš”ì•½ (ë‹¨ìœ„: ì›)\n"
        for month in sorted(income_grp.index):
            inc = income_grp.get(month, 0)
            exp = expense_grp.get(month, 0)
            profit = inc - exp
            summary_text += f"- {month}ì›”: ìˆ˜ì… {inc:,.0f}, ì§€ì¶œ {exp:,.0f}, ìˆœìˆ˜ìµ {profit:,.0f}\n"

        detail_col = next((col for col in df.columns if col in ['ë‚´ì—­', 'ì ìš”', 'ìƒì„¸', 'ë¹„ê³ ']), None)
        top_expenses_text = ""
        if detail_col:
            high_cost_items = df[df['ëŒ€ë¶„ë¥˜'] == 'ê³ ì •ë¹„ìš©'].sort_values(by='ê¸ˆì•¡', ascending=False).head(10)
            top_expenses_text = "\n### ì˜¬í•´ì˜ ì£¼ìš” ê³ ì •ë¹„ ì§€ì¶œ ë‚´ì—­ (ì°¸ê³ ìš©):\n"
            for _, row in high_cost_items.iterrows():
                top_expenses_text += f"- {row['ì›”']}ì›” [{row[detail_col]}]: {row['ê¸ˆì•¡']:,.0f}ì›\n"

        return f"{summary_text}\n{top_expenses_text}\n\nì‚¬ìš©ì ì§ˆë¬¸: {question}"
    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# --- ë©”ì¸ í™”ë©´ êµ¬ì„± ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3022/3022709.png", width=80)
    st.title("ğŸ’Š ì•½êµ­ ë¹„ì„œ")
    st.markdown("---")
    uploaded_file = st.file_uploader("ğŸ“‚ ì—‘ì…€ ê°€ê³„ë¶€ íŒŒì¼ ì—…ë¡œë“œ", type=['xlsx'])
    st.markdown("### ğŸ’¡ íŒ")
    st.info("""
    **ì§ˆë¬¸ ì˜ˆì‹œ:**
    - "ì´ë²ˆ ë‹¬ ìˆœìˆ˜ìµ ì–¼ë§ˆì•¼?"
    - "8ì›”ì— ì§€ì¶œì´ ì™œ ì´ë ‡ê²Œ ì»¤?"
    """)

st.title("ğŸ’Š ì—„ë§ˆë¥¼ ìœ„í•œ ì•½êµ­ ë˜‘ë˜‘ì´ ë¹„ì„œ")

if uploaded_file:
    try:
        if 'df' not in st.session_state or st.session_state.get('file_name') != uploaded_file.name:
            df = pd.read_excel(uploaded_file)
            st.session_state['df'] = df
            st.session_state['file_name'] = uploaded_file.name
        else:
            df = st.session_state['df']

        df['ê¸ˆì•¡'] = pd.to_numeric(df['ê¸ˆì•¡'], errors='coerce').fillna(0)
        
        all_years = sorted(df['ë…„'].unique(), reverse=True)
        col_filter, _ = st.columns([1, 3])
        with col_filter:
            selected_year = st.selectbox("ğŸ“… ì—°ë„ ì„ íƒ", all_years)
            st.session_state['selected_year'] = selected_year

        df_year = df[df['ë…„'] == selected_year]
        income_sum = df_year[df_year['ëŒ€ë¶„ë¥˜'] == 'ìˆ˜ì…'].groupby('ì›”')['ê¸ˆì•¡'].sum()
        fixed_sum = df_year[df_year['ëŒ€ë¶„ë¥˜'] == 'ê³ ì •ë¹„ìš©'].groupby('ì›”')['ê¸ˆì•¡'].sum()
        drug_sum = df_year[df_year['ëŒ€ë¶„ë¥˜'] == 'ì˜ì•½í’ˆ_êµ¬ì…ë¹„'].groupby('ì›”')['ê¸ˆì•¡'].sum()
        
        summary = pd.concat([income_sum, fixed_sum, drug_sum], axis=1)
        summary.columns = ['ìˆ˜ì…', 'ê³ ì •ë¹„ìš©', 'ì˜ì•½í’ˆ_êµ¬ì…ë¹„']
        summary = summary.fillna(0)
        summary['ì´ì§€ì¶œ'] = summary['ê³ ì •ë¹„ìš©'] + summary['ì˜ì•½í’ˆ_êµ¬ì…ë¹„']
        summary['ìˆœìˆ˜ìµ'] = summary['ìˆ˜ì…'] - summary['ì´ì§€ì¶œ']

        st.markdown(f"### ğŸ† {selected_year}ë…„ ì„±ì í‘œ")
        kpi1, kpi2, kpi3 = st.columns(3)
        kpi1.metric("ì´ ìˆœìˆ˜ìµ", f"{summary['ìˆœìˆ˜ìµ'].sum():,.0f}ì›")
        kpi2.metric("ì›” í‰ê·  ìˆœìˆ˜ìµ", f"{summary['ìˆœìˆ˜ìµ'].mean():,.0f}ì›")
        kpi3.metric("ìµœê³ ì˜ ë‹¬", f"{summary['ìˆœìˆ˜ìµ'].idxmax()}ì›”", f"ğŸ’° +{summary['ìˆœìˆ˜ìµ'].max():,.0f}ì›")
        st.markdown("---")

        tab1, tab2 = st.tabs(["ğŸ“Š ìˆ˜ì… vs ì§€ì¶œ íë¦„", "ğŸ° ê³ ì •ë¹„ìš© ë¶„ì„"])
        with tab1:
            st.subheader("ë“¤ì–´ì˜¨ ëˆ(ìˆ˜ì…) vs ë‚˜ê°„ ëˆ(ì§€ì¶œ)")
            chart_data = summary.reset_index()
            bar = alt.Chart(chart_data).mark_bar(color='#a7f3d0').encode(
                x=alt.X('ì›”:O'), y=alt.Y('ìˆ˜ì…:Q'), tooltip=['ì›”', 'ìˆ˜ì…']
            )
            line = alt.Chart(chart_data).mark_line(color='#ef4444', point=True).encode(
                x='ì›”:O', y='ì´ì§€ì¶œ:Q', tooltip=['ì›”', 'ì´ì§€ì¶œ']
            )
            st.altair_chart((bar + line).interactive(), use_container_width=True)

        with tab2:
            st.subheader("ê³ ì •ë¹„ìš© ë¶„ì„")
            cat_col = 'ì¤‘ë¶„ë¥˜' if 'ì¤‘ë¶„ë¥˜' in df_year.columns else ('ë‚´ì—­' if 'ë‚´ì—­' in df_year.columns else None)
            if cat_col:
                pie_data = df_year[df_year['ëŒ€ë¶„ë¥˜'] == 'ê³ ì •ë¹„ìš©'].groupby(cat_col)['ê¸ˆì•¡'].sum().reset_index()
                pie = alt.Chart(pie_data).mark_arc(innerRadius=50).encode(
                    theta='ê¸ˆì•¡', color=cat_col, tooltip=[cat_col, 'ê¸ˆì•¡']
                )
                st.altair_chart(pie, use_container_width=True)
            else:
                st.info("ìƒì„¸ ë‚´ì—­(ì¤‘ë¶„ë¥˜/ë‚´ì—­)ì´ ì—†ì–´ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("---")
        st.subheader("ğŸ’¬ ì—„ë§ˆë¥¼ ìœ„í•œ AI ë¹„ì„œ")
        
        if "messages" not in st.session_state:
            st.session_state.messages = []

        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                msg_box = st.empty()
                msg_box.markdown("ë¹„ì„œê°€ ì¥ë¶€ë¥¼ ë³´ëŠ” ì¤‘... ğŸ§")
                try:
                    llm = initialize_llm(api_key)
                    tools = [analyze_financial_data]
                    prompt_template = ChatPromptTemplate.from_messages([
                        ("system", "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì•½êµ­ íšŒê³„ ë¹„ì„œì…ë‹ˆë‹¤. ê¸ˆì•¡ì— ì½¤ë§ˆë¥¼ ì°ì–´ ë‹µë³€í•˜ì„¸ìš”."),
                        ("human", "{input}"),
                        MessagesPlaceholder(variable_name="agent_scratchpad"),
                    ])
                    agent = create_tool_calling_agent(llm, tools, prompt_template)
                    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)
                    response = agent_executor.invoke({"input": prompt})
                    msg_box.markdown(response['output'])
                    st.session_state.messages.append({"role": "assistant", "content": response['output']})
                except Exception as e:
                    msg_box.error(f"ì˜¤ë¥˜: {e}")

    except Exception as e:
        st.error(f"íŒŒì¼ ì˜¤ë¥˜: {e}")

else:
    col1, col2 = st.columns([1, 2])
    with col1:
        st.image("https://cdn-icons-png.flaticon.com/512/3022/3022709.png", width=150)
    with col2:
        st.markdown("""
        ## í™˜ì˜í•©ë‹ˆë‹¤! ğŸ‘‹
        ì–´ë¨¸ë‹ˆ, ì•½êµ­ ìš´ì˜í•˜ì‹œëŠë¼ ê³ ìƒ ë§ìœ¼ì…¨ì£ ?
        **ğŸ‘ˆ ì™¼ìª½ì—ì„œ ì—‘ì…€ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.**
        """)
